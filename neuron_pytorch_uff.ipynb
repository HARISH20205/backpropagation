{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: graphviz in c:\\users\\harish k b\\appdata\\roaming\\python\\python312\\site-packages (0.20.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "%pip install graphviz\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from graphviz import Digraph\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "    # builds a set of all nodes and edges in a graph\n",
    "    nodes, edges = set(), set()\n",
    "    \n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "    \n",
    "    nodes, edges = trace(root)\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        # for any value in the graph, create a rectangular ('record') node for it\n",
    "        dot.node(name = uid, label = \"{ %s |  data %4f}\" % (n.data,n.grad), shape='record')\n",
    "        # if this value is a result of some operation, create an op node for it\n",
    "        if n._op:\n",
    "            dot.node(name = uid + n._op, label = n._op)\n",
    "            dot.edge(uid + n._op, uid)\n",
    "    for n1, n2 in edges:\n",
    "        # connect n1 to the op node of n2\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    \n",
    "    return dot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9995503665024041\n",
      "-0.0008990648249095345\n",
      "0.0\n",
      "0.0008990648249095345\n",
      "0.001798129649819069\n"
     ]
    }
   ],
   "source": [
    "x1 = torch.Tensor([1.0]).double()\n",
    "x1.requires_grad = True\n",
    "\n",
    "x2 = torch.Tensor([0.0]).double()\n",
    "x2.requires_grad = True\n",
    "\n",
    "w1 = torch.Tensor([2.0]).double()\n",
    "w1.requires_grad = True\n",
    "\n",
    "w2 = torch.Tensor([-1.0]).double()\n",
    "w2.requires_grad = True\n",
    "\n",
    "b = torch.Tensor([2.2]).double()\n",
    "b.requires_grad = True\n",
    "\n",
    "n = x1 * w1 + x2 * w2 + b\n",
    "o = torch.tanh(n)\n",
    "\n",
    "print(o.data.item())\n",
    "o.backward()\n",
    "\n",
    "print(x2.grad.item())\n",
    "print(w2.grad.item())\n",
    "print(w1.grad.item())\n",
    "print(x1.grad.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Value:\n",
    "    \"\"\" stores a single scalar value and its gradient \"\"\"\n",
    "\n",
    "    def __init__(self, data, _children=(), _op=''):\n",
    "        self.data = data\n",
    "        self.grad = 0\n",
    "        # internal variables used for autograd graph construction\n",
    "        self._backward = lambda: None\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op # the op that produced this node, for graphviz / debugging / etc\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data + other.data, (self, other), '+')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += out.grad\n",
    "            other.grad += out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, (self, other), '*')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "        out = Value(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (other * self.data**(other-1)) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def relu(self):\n",
    "        out = Value(0 if self.data < 0 else self.data, (self,), 'ReLU')\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (out.data > 0) * out.grad\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "\n",
    "        # topological order all of the children in the graph\n",
    "        topo = []\n",
    "        visited = set()\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "        build_topo(self)\n",
    "\n",
    "        # go one variable at a time and apply the chain rule to get its gradient\n",
    "        self.grad = 1\n",
    "        for v in reversed(topo):\n",
    "            v._backward()\n",
    "\n",
    "    def __neg__(self): # -self\n",
    "        return self * -1\n",
    "\n",
    "    def __radd__(self, other): # other + self\n",
    "        return self + other\n",
    "\n",
    "    def __sub__(self, other): # self - other\n",
    "        return self + (-other)\n",
    "\n",
    "    def __rsub__(self, other): # other - self\n",
    "        return other + (-self)\n",
    "\n",
    "    def __rmul__(self, other): # other * self\n",
    "        return self * other\n",
    "\n",
    "    def __truediv__(self, other): # self / other\n",
    "        return self * other**-1\n",
    "\n",
    "    def __rtruediv__(self, other): # other / self\n",
    "        return other * self**-1\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data}, grad={self.grad})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron():\n",
    "    def __init__(self, nin):\n",
    "        self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)]\n",
    "        self.b = Value(1.0)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        act = sum((wi * xi for wi, xi in zip(self.w, x)), self.b)\n",
    "        return act\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.w + [self.b]\n",
    "\n",
    "\n",
    "class Layer():\n",
    "    def __init__(self, nin, nout):\n",
    "        self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        outs = [n(x) for n in self.neurons]\n",
    "        return outs[0] if len(outs) == 1 else outs\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "\n",
    "class MLP():\n",
    "    def __init__(self, nin, nouts):\n",
    "        sz = [nin] + nouts\n",
    "        self.layers = [Layer(sz[i], sz[i + 1]) for i in range(len(nouts))]\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    def parameters(self):\n",
    "        return [p for layer in self.layers for p in layer.parameters()]\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=-0.5777597241023255, grad=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [1,-2,4]\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [\n",
    "[2.0, 2.0, -1.0],\n",
    "[1.0, 1.0, 0.5],\n",
    "[1.0, 1.0, -1.0],\n",
    "[0.5,2.0,-1.5]\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=4.415740893797561, grad=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [n(x) for x in xs]\n",
    "loss  =  sum([(yout-ygt)**2 for ygt,yout in zip(ys,ypred)])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(data=4.415740893797561, grad=0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = [n(x) for x in xs]\n",
    "loss  =  sum([(yout-ygt)**2 for ygt,yout in zip(ys,ypred)])\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in n.parameters():\n",
    "    p.data +=-0.00001 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=0.11034065228999192, grad=0)\n",
      "Value(data=0.11188528989099612, grad=0)\n",
      "Value(data=0.1135500786293937, grad=0)\n",
      "Value(data=0.11533456494622277, grad=0)\n",
      "Value(data=0.117238261308903, grad=0)\n",
      "Value(data=0.11926064663243935, grad=0)\n",
      "Value(data=0.12140116670819623, grad=0)\n",
      "Value(data=0.12365923463997441, grad=0)\n",
      "Value(data=0.12603423128710975, grad=0)\n",
      "Value(data=0.12852550571432778, grad=0)\n",
      "Value(data=0.13113237564807895, grad=0)\n",
      "Value(data=0.13385412793909648, grad=0)\n",
      "Value(data=0.13669001903090755, grad=0)\n",
      "Value(data=0.13963927543404225, grad=0)\n",
      "Value(data=0.1427010942056845, grad=0)\n",
      "Value(data=0.14587464343450776, grad=0)\n",
      "Value(data=0.14915906273045204, grad=0)\n",
      "Value(data=0.15255346371919032, grad=0)\n",
      "Value(data=0.156056930541045, grad=0)\n",
      "Value(data=0.1596685203541115, grad=0)\n",
      "Value(data=0.1633872638413557, grad=0)\n",
      "Value(data=0.1672121657214483, grad=0)\n",
      "Value(data=0.17114220526311233, grad=0)\n",
      "Value(data=0.17517633680274922, grad=0)\n",
      "Value(data=0.1793134902651274, grad=0)\n",
      "Value(data=0.18355257168691244, grad=0)\n",
      "Value(data=0.18789246374281593, grad=0)\n",
      "Value(data=0.19233202627416437, grad=0)\n",
      "Value(data=0.19687009681966033, grad=0)\n",
      "Value(data=0.20150549114814498, grad=0)\n",
      "Value(data=0.20623700379315135, grad=0)\n",
      "Value(data=0.2110634085890516, grad=0)\n",
      "Value(data=0.21598345920859913, grad=0)\n",
      "Value(data=0.2209958897016747, grad=0)\n",
      "Value(data=0.2260994150350507, grad=0)\n",
      "Value(data=0.2312927316329775, grad=0)\n",
      "Value(data=0.23657451791841536, grad=0)\n",
      "Value(data=0.24194343485473477, grad=0)\n",
      "Value(data=0.24739812648769907, grad=0)\n",
      "Value(data=0.2529372204875632, grad=0)\n",
      "Value(data=0.25855932869111387, grad=0)\n",
      "Value(data=0.26426304764348596, grad=0)\n",
      "Value(data=0.27004695913958954, grad=0)\n",
      "Value(data=0.2759096307649844, grad=0)\n",
      "Value(data=0.28184961643604683, grad=0)\n",
      "Value(data=0.28786545693926824, grad=0)\n",
      "Value(data=0.29395568046953924, grad=0)\n",
      "Value(data=0.30011880316726103, grad=0)\n",
      "Value(data=0.3063533296541443, grad=0)\n",
      "Value(data=0.31265775356754816, grad=0)\n",
      "Value(data=0.31903055809321673, grad=0)\n",
      "Value(data=0.3254702164962735, grad=0)\n",
      "Value(data=0.33197519265034486, grad=0)\n",
      "Value(data=0.33854394156466366, grad=0)\n",
      "Value(data=0.34517490990904354, grad=0)\n",
      "Value(data=0.35186653653657146, grad=0)\n",
      "Value(data=0.35861725300391345, grad=0)\n",
      "Value(data=0.365425484089096, grad=0)\n",
      "Value(data=0.3722896483066484, grad=0)\n",
      "Value(data=0.3792081584199864, grad=0)\n",
      "Value(data=0.3861794219509211, grad=0)\n",
      "Value(data=0.3932018416861771, grad=0)\n",
      "Value(data=0.4002738161808109, grad=0)\n",
      "Value(data=0.40739374025841907, grad=0)\n",
      "Value(data=0.4145600055080299, grad=0)\n",
      "Value(data=0.4217710007775701, grad=0)\n",
      "Value(data=0.4290251126638088, grad=0)\n",
      "Value(data=0.43632072599867733, grad=0)\n",
      "Value(data=0.4436562243318605, grad=0)\n",
      "Value(data=0.451029990409571, grad=0)\n",
      "Value(data=0.4584404066494094, grad=0)\n",
      "Value(data=0.4658858556112132, grad=0)\n",
      "Value(data=0.4733647204638083, grad=0)\n",
      "Value(data=0.48087538544758296, grad=0)\n",
      "Value(data=0.4884162363327756, grad=0)\n",
      "Value(data=0.495985660873415, grad=0)\n",
      "Value(data=0.5035820492568219, grad=0)\n",
      "Value(data=0.5112037945485791, grad=0)\n",
      "Value(data=0.5188492931329154, grad=0)\n",
      "Value(data=0.5265169451484021, grad=0)\n",
      "Value(data=0.5342051549189066, grad=0)\n",
      "Value(data=0.5419123313797125, grad=0)\n",
      "Value(data=0.5496368884987476, grad=0)\n",
      "Value(data=0.5573772456928424, grad=0)\n",
      "Value(data=0.5651318282389542, grad=0)\n",
      "Value(data=0.5728990676802885, grad=0)\n",
      "Value(data=0.5806774022272521, grad=0)\n",
      "Value(data=0.5884652771531813, grad=0)\n",
      "Value(data=0.5962611451847687, grad=0)\n",
      "Value(data=0.6040634668871518, grad=0)\n",
      "Value(data=0.6118707110435819, grad=0)\n",
      "Value(data=0.6196813550296315, grad=0)\n",
      "Value(data=0.6274938851818774, grad=0)\n",
      "Value(data=0.6353067971610181, grad=0)\n",
      "Value(data=0.6431185963093572, grad=0)\n",
      "Value(data=0.6509277980026148, grad=0)\n",
      "Value(data=0.6587329279960155, grad=0)\n",
      "Value(data=0.666532522764607, grad=0)\n",
      "Value(data=0.6743251298377634, grad=0)\n",
      "Value(data=0.6821093081278271, grad=0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss  =  sum([(yout-ygt)**2 for ygt,yout in zip(ys,ypred)])\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    for p in n.parameters():\n",
    "        p.data +=-0.000001 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=1.2530236891641915, grad=0)\n",
      "Value(data=1.2519537866780364, grad=0)\n",
      "Value(data=1.250884329695333, grad=0)\n",
      "Value(data=1.249815914031227, grad=0)\n",
      "Value(data=1.2487491285520997, grad=0)\n",
      "Value(data=1.2476845550574447, grad=0)\n",
      "Value(data=1.246622768163938, grad=0)\n",
      "Value(data=1.2455643351917138, grad=0)\n",
      "Value(data=1.2445098160528263, grad=0)\n",
      "Value(data=1.2434597631418947, grad=0)\n",
      "Value(data=1.2424147212289258, grad=0)\n",
      "Value(data=1.2413752273543124, grad=0)\n",
      "Value(data=1.2403418107259865, grad=0)\n",
      "Value(data=1.2393149926187306, grad=0)\n",
      "Value(data=1.2382952862756378, grad=0)\n",
      "Value(data=1.2372831968117093, grad=0)\n",
      "Value(data=1.236279221119578, grad=0)\n",
      "Value(data=1.235283847777359, grad=0)\n",
      "Value(data=1.2342975569586045, grad=0)\n",
      "Value(data=1.2333208203443695, grad=0)\n",
      "Value(data=1.2323541010373618, grad=0)\n",
      "Value(data=1.2313978534781767, grad=0)\n",
      "Value(data=1.230452523363609, grad=0)\n",
      "Value(data=1.2295185475670225, grad=0)\n",
      "Value(data=1.2285963540607734, grad=0)\n",
      "Value(data=1.2276863618406755, grad=0)\n",
      "Value(data=1.2267889808524997, grad=0)\n",
      "Value(data=1.225904611920489, grad=0)\n",
      "Value(data=1.2250336466778915, grad=0)\n",
      "Value(data=1.2241764674994853, grad=0)\n",
      "Value(data=1.2233334474361017, grad=0)\n",
      "Value(data=1.2225049501511207, grad=0)\n",
      "Value(data=1.2216913298589338, grad=0)\n",
      "Value(data=1.2208929312653756, grad=0)\n",
      "Value(data=1.220110089510087, grad=0)\n",
      "Value(data=1.219343130110827, grad=0)\n",
      "Value(data=1.2185923689097078, grad=0)\n",
      "Value(data=1.217858112021346, grad=0)\n",
      "Value(data=1.2171406557829167, grad=0)\n",
      "Value(data=1.2164402867061102, grad=0)\n",
      "Value(data=1.2157572814309685, grad=0)\n",
      "Value(data=1.2150919066816037, grad=0)\n",
      "Value(data=1.214444419223779, grad=0)\n",
      "Value(data=1.2138150658243494, grad=0)\n",
      "Value(data=1.2132040832125492, grad=0)\n",
      "Value(data=1.2126116980431185, grad=0)\n",
      "Value(data=1.2120381268612612, grad=0)\n",
      "Value(data=1.2114835760694231, grad=0)\n",
      "Value(data=1.2109482418958835, grad=0)\n",
      "Value(data=1.210432310365149, grad=0)\n",
      "Value(data=1.2099359572701498, grad=0)\n",
      "Value(data=1.2094593481462184, grad=0)\n",
      "Value(data=1.2090026382468515, grad=0)\n",
      "Value(data=1.2085659725212492, grad=0)\n",
      "Value(data=1.2081494855936181, grad=0)\n",
      "Value(data=1.2077533017442352, grad=0)\n",
      "Value(data=1.2073775348922646, grad=0)\n",
      "Value(data=1.2070222885803255, grad=0)\n",
      "Value(data=1.2066876559607986, grad=0)\n",
      "Value(data=1.2063737197838689, grad=0)\n",
      "Value(data=1.2060805523873017, grad=0)\n",
      "Value(data=1.205808215687941, grad=0)\n",
      "Value(data=1.2055567611749323, grad=0)\n",
      "Value(data=1.2053262299046612, grad=0)\n",
      "Value(data=1.2051166524974026, grad=0)\n",
      "Value(data=1.2049280491356802, grad=0)\n",
      "Value(data=1.2047604295643337, grad=0)\n",
      "Value(data=1.204613793092284, grad=0)\n",
      "Value(data=1.204488128595998, grad=0)\n",
      "Value(data=1.2043834145246544, grad=0)\n",
      "Value(data=1.2042996189070023, grad=0)\n",
      "Value(data=1.2042366993599063, grad=0)\n",
      "Value(data=1.2041946030985908, grad=0)\n",
      "Value(data=1.204173266948573, grad=0)\n",
      "Value(data=1.2041726173592757, grad=0)\n",
      "Value(data=1.2041925704193412, grad=0)\n",
      "Value(data=1.204233031873621, grad=0)\n",
      "Value(data=1.2042938971418602, grad=0)\n",
      "Value(data=1.2043750513390679, grad=0)\n",
      "Value(data=1.2044763692975708, grad=0)\n",
      "Value(data=1.2045977155907663, grad=0)\n",
      "Value(data=1.2047389445585517, grad=0)\n",
      "Value(data=1.204899900334456, grad=0)\n",
      "Value(data=1.2050804168744615, grad=0)\n",
      "Value(data=1.2052803179875138, grad=0)\n",
      "Value(data=1.2054994173677385, grad=0)\n",
      "Value(data=1.2057375186283494, grad=0)\n",
      "Value(data=1.2059944153372637, grad=0)\n",
      "Value(data=1.2062698910544185, grad=0)\n",
      "Value(data=1.2065637193707939, grad=0)\n",
      "Value(data=1.206875663949154, grad=0)\n",
      "Value(data=1.2072054785664945, grad=0)\n",
      "Value(data=1.2075529071582147, grad=0)\n",
      "Value(data=1.2079176838640107, grad=0)\n",
      "Value(data=1.2082995330754893, grad=0)\n",
      "Value(data=1.2086981694855254, grad=0)\n",
      "Value(data=1.2091132981393407, grad=0)\n",
      "Value(data=1.2095446144873336, grad=0)\n",
      "Value(data=1.2099918044396492, grad=0)\n",
      "Value(data=1.2104545444224992, grad=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Value(data=0.506361582235045, grad=-0.98727683552991),\n",
       " Value(data=-0.354698036586124, grad=1.290603926827752),\n",
       " Value(data=-0.5028602504466197, grad=0.9942794991067605),\n",
       " Value(data=0.4493521067349753, grad=-1.1012957865300494)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    #forward pass\n",
    "    ypred = [n(x) for x in xs]\n",
    "    loss  =  sum([(yout-ygt)**2 for ygt,yout in zip(ys,ypred)])\n",
    "    print(loss)\n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    #update\n",
    "    for p in n.parameters():\n",
    "        p.data +=-0.000001 * p.grad\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
